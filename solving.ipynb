{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22497278  0.          0.          0.          0.        ]\n",
      " [ 0.46892257  0.74807277  0.          0.          0.        ]\n",
      " [ 0.66670839 -0.55772129 -1.12222946  0.          0.        ]\n",
      " [ 0.8884206  -0.10084119 -0.14638602  0.41325135  0.        ]\n",
      " [ 0.99743608 -0.68464543  0.20622565  0.50372726 -0.30423685]]\n",
      "sol: [0.81634467 0.         0.         0.         0.        ]\n",
      "sol: [0.81634467 0.82505016 0.         0.         0.        ]\n",
      "sol: [0.81634467 0.82505016 0.07495419 0.         0.        ]\n",
      "sol: [ 0.81634467  0.82505016  0.07495419 -1.52712419  0.        ]\n",
      "sol: [ 0.81634467  0.82505016  0.07495419 -1.52712419 -1.65795761]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.22044605e-16])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lx = b\n",
    "\n",
    "L = np.tril(np.random.randn(5, 5))\n",
    "print(L)\n",
    "\n",
    "b = np.array([1, 1, 0, 0, 0], dtype=float)\n",
    "\n",
    "\n",
    "def forward_substitute(L, b):\n",
    "    sol = np.zeros_like(b)\n",
    "    for i in range(L.shape[1]):\n",
    "        sol[i] = (b[i] - np.dot(L[i, :i], sol[:i])) / L[i, i]\n",
    "        print(\"sol:\", sol)\n",
    "    return sol\n",
    "\n",
    "\n",
    "x = forward_substitute(L, b)\n",
    "L @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanczos Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\n",
      "[[ 2.15894538  2.21640305  0.          0.          0.        ]\n",
      " [ 2.21640305 -1.54194762  2.32437696  0.          0.        ]\n",
      " [ 0.          2.32437696  2.61173191  0.83624853  0.        ]\n",
      " [ 0.          0.          0.83624853 -2.78087231  0.08645143]\n",
      " [ 0.          0.          0.          0.08645143  2.57972387]]\n",
      "Q\n",
      "[[ 1.          0.          0.         -0.         -0.        ]\n",
      " [ 0.         -0.31431629 -0.19752588 -0.27795007 -0.8859642 ]\n",
      " [ 0.         -0.34551712 -0.6739704   0.6493088   0.06913691]\n",
      " [ 0.         -0.5952016  -0.24050336 -0.61510382  0.45775591]\n",
      " [ 0.         -0.65387938  0.67000415  0.35041281 -0.02733235]]\n"
     ]
    }
   ],
   "source": [
    "A_M = np.random.randn(5, 5)\n",
    "A_M += A_M.T\n",
    "q1 = np.array([1, 0, 0, 0, 0], float)\n",
    "\n",
    "qs_v = [np.zeros_like(q1)]\n",
    "as_s = []\n",
    "bs_s = [1]\n",
    "r = q1\n",
    "for k in range(5):\n",
    "    # extract q as the normalized vector\n",
    "    qs_v += (r / bs_s[-1],)\n",
    "\n",
    "    # compute next alpha\n",
    "    as_s += (qs_v[-1] @ A_M @ qs_v[-1],)\n",
    "\n",
    "    # isolate q_k-1 * beta_k-1\n",
    "    r = A_M @ qs_v[-1] - as_s[-1] * qs_v[-1] - bs_s[-1] * qs_v[-2]\n",
    "    norm = np.linalg.norm(r)\n",
    "    if np.allclose(norm, 0, 1e-8):\n",
    "        break\n",
    "    # extract beta as the norm\n",
    "    bs_s += (norm,)\n",
    "\n",
    "\n",
    "H = np.zeros((k + 1, k + 1))\n",
    "H += np.diag(as_s)\n",
    "H += np.diag(bs_s[1:], k=1)\n",
    "H += np.diag(bs_s[1:], k=-1)\n",
    "\n",
    "Q = np.array(qs_v[1:]).T\n",
    "print(\"H:\")\n",
    "print((H).round(10))\n",
    "\n",
    "print(\"Q\")\n",
    "print((Q).round(10))\n",
    "# print((Q.T @ Q).round(10))\n",
    "\n",
    "# print((Q@H@Q.T-A_M).round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidiagonalization (cooler Lanczos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import jax\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class BidiagResult:\n",
    "    rs: list[list[float]]\n",
    "    ls: list[list[float]]\n",
    "    L: int\n",
    "    B: int\n",
    "    R: int\n",
    "    alphas: list[float]\n",
    "    betas: list[float]\n",
    "    c: float\n",
    "\n",
    "\n",
    "def bidiagonalize(A, start_vector) -> BidiagResult:\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "\n",
    "    any_n_vec = np.zeros(n)\n",
    "    any_m_vec = np.zeros(m)\n",
    "    any_number = 0\n",
    "    betas = [0]\n",
    "    alphas = [any_number]\n",
    "\n",
    "    c = 1 / np.linalg.norm(start_vector)\n",
    "    r_columns = [any_n_vec, start_vector * c]\n",
    "    l_columns = [any_m_vec]\n",
    "\n",
    "    for k in range(1, max(n, m) + 1):\n",
    "        t = A @ r_columns[k] - betas[k - 1] * l_columns[k - 1]\n",
    "        alpha_k = np.linalg.norm(t)\n",
    "        alphas.append(alpha_k)\n",
    "        l_k = t / alpha_k\n",
    "        l_columns.append(l_k)\n",
    "\n",
    "        w = A.T @ l_k - alpha_k * r_columns[k]\n",
    "        beta_k = np.linalg.norm(w)\n",
    "        betas.append(beta_k)\n",
    "\n",
    "        r_kp1 = w / beta_k\n",
    "        r_columns.append(r_kp1)\n",
    "\n",
    "        if np.allclose(beta_k, 0, atol=1e-10) or np.isnan(beta_k):\n",
    "            break\n",
    "\n",
    "    L = np.array(l_columns[1:]).T\n",
    "    R = np.array(r_columns[1:-1]).T\n",
    "    B = np.diag(alphas[1:]) + np.diag(betas[1:-1], k=1)\n",
    "\n",
    "    return BidiagResult(\n",
    "        ls=l_columns, rs=r_columns, L=L, B=B, R=R, alphas=alphas, betas=betas, c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L^TL and R^TR:\n",
      "[[1.00e+00 2.78e-17]\n",
      " [2.78e-17 1.00e+00]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "A vs LBR^T:\n",
      "[[ 0.63  1.82]\n",
      " [-1.21  0.23]\n",
      " [ 1.20  0.36]]\n",
      "[[ 0.63  1.82]\n",
      " [-1.21  0.23]\n",
      " [ 1.20  0.36]]\n",
      "\n",
      "AR vs LB:\n",
      "[[ 0.63  1.82]\n",
      " [-1.21  0.23]\n",
      " [ 1.20  0.36]]\n",
      "[[ 0.63  1.82]\n",
      " [-1.21  0.23]\n",
      " [ 1.20  0.36]]\n",
      "Reconstruction is good: True\n"
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "n = 2\n",
    "\n",
    "A = np.random.randn(m, n)\n",
    "start_vector = 2 * np.eye(1, n).flatten()\n",
    "\n",
    "result = bidiagonalize(A, start_vector)\n",
    "L = result.L\n",
    "B = result.B\n",
    "R = result.R\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"L^TL and R^TR:\")\n",
    "print(np.array2string(L.T @ L, precision=2, floatmode=\"maxprec_equal\"))\n",
    "print(np.array2string(R.T @ R, precision=2, floatmode=\"maxprec_equal\"))\n",
    "\n",
    "print()\n",
    "print(\"A vs LBR^T:\")\n",
    "print(np.array2string(L @ B @ R.T, precision=2, floatmode=\"maxprec_equal\"))\n",
    "print(np.array2string(A, precision=2, floatmode=\"maxprec_equal\"))\n",
    "\n",
    "print()\n",
    "print(\"AR vs LB:\")\n",
    "print(np.array2string(A @ R, precision=2, floatmode=\"maxprec_equal\"))\n",
    "print(np.array2string(L @ B, precision=2, floatmode=\"maxprec_equal\"))\n",
    "\n",
    "\n",
    "are_close = np.allclose(A, L @ B @ R.T, atol=1e-5)\n",
    "print(\"Reconstruction is good:\", are_close)\n",
    "assert are_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidiagonalize_jvp(primals, tangents) -> tuple[BidiagResult, BidiagResult]:\n",
    "    A, start_vector = primals\n",
    "    dA, d_start_vector = tangents\n",
    "\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "\n",
    "    any_n_vec = np.zeros(n)\n",
    "    any_m_vec = np.zeros(m)\n",
    "    any_number = 0\n",
    "    bs = [0]\n",
    "    as_ = [any_number]\n",
    "\n",
    "    c = 1 / np.linalg.norm(start_vector)\n",
    "    rs = [any_n_vec, start_vector * c]\n",
    "    ls = [any_m_vec]\n",
    "\n",
    "    for k in range(1, max(n, m) + 1):\n",
    "        t = A @ rs[k] - bs[k - 1] * ls[k - 1]\n",
    "        alpha_k = np.linalg.norm(t)\n",
    "        as_.append(alpha_k)\n",
    "        l_k = t / alpha_k\n",
    "        ls.append(l_k)\n",
    "\n",
    "        w = A.T @ l_k - alpha_k * rs[k]\n",
    "        beta_k = np.linalg.norm(w)\n",
    "        bs.append(beta_k)\n",
    "\n",
    "        r_kp1 = w / beta_k\n",
    "        rs.append(r_kp1)\n",
    "\n",
    "        if np.allclose(beta_k, 0, atol=1e-10) or np.isnan(beta_k):\n",
    "            break\n",
    "\n",
    "    L = np.array(ls[1:]).T\n",
    "    R = np.array(rs[1:-1]).T\n",
    "    B = np.diag(as_[1:]) + np.diag(bs[1:-1], k=1)\n",
    "\n",
    "    primal_output = BidiagResult(rs=rs, ls=ls, L=L, B=B, R=R, alphas=as_, betas=bs, c=c)\n",
    "\n",
    "    d_as = [0] * len(as_)\n",
    "    d_bs = [0] * len(bs)\n",
    "    d_rs = [any_n_vec] * (len(rs))\n",
    "    d_rs[1] = (\n",
    "        d_start_vector\n",
    "        - start_vector\n",
    "        * (\n",
    "            start_vector.T @ d_start_vector\n",
    "        )  # This should be corrected for when start vector is not unit length\n",
    "    ) / np.linalg.norm(start_vector)\n",
    "    d_ls = [any_m_vec * 0] * (len(ls))\n",
    "\n",
    "    # d_rs[1] = d_start_vector, known\n",
    "    # d_ls[0] = doesn't matter because bs_[0] = 0\n",
    "    # d_bs[0] = 0\n",
    "\n",
    "    # In each iteration, assume we already know d_rs[n], d_ls[n-1], d_bs[n-1]\n",
    "    for n in range(1, len(as_)):\n",
    "        d_a_n = ls[n].T @ (A @ d_rs[n] + dA @ rs[n] - d_ls[n - 1] * bs[n - 1])\n",
    "        d_as[n] = d_a_n\n",
    "        d_l_n = (\n",
    "            A @ d_rs[n]\n",
    "            + dA @ rs[n]\n",
    "            - ls[n] * d_as[n]\n",
    "            - ls[n - 1] * d_bs[n - 1]\n",
    "            + d_ls[n - 1] * bs[n - 1]\n",
    "        ) / as_[n]\n",
    "        d_ls[n] = d_l_n\n",
    "        d_b_n = (\n",
    "            rs[n + 1].T @ A.T @ d_ls[n]\n",
    "            + rs[n + 1].T @ dA.T @ ls[n]\n",
    "            - rs[n + 1].T @ d_rs[n] * as_[n]\n",
    "        )\n",
    "        d_bs[n] = d_b_n\n",
    "        d_rs[n + 1] = (\n",
    "            A.T @ d_ls[n]\n",
    "            + dA.T @ ls[n]\n",
    "            - rs[n] * d_as[n]\n",
    "            - rs[n + 1] * d_bs[n]\n",
    "            - d_rs[n] * as_[n]\n",
    "        ) / d_bs[n]\n",
    "\n",
    "    d_c = (\n",
    "        -(start_vector @ d_start_vector)\n",
    "        / (start_vector @ start_vector)\n",
    "        * np.linalg.norm(start_vector)\n",
    "    )\n",
    "\n",
    "    dL = np.array(d_ls[1:]).T\n",
    "    dR = np.array(d_rs[1:-1]).T\n",
    "    dB = np.diag(d_as[1:]) + np.diag(d_bs[1:-1], k=1)  # beta index -1?\n",
    "\n",
    "    tangent_output = BidiagResult(\n",
    "        rs=d_rs, ls=d_ls, L=dL, B=dB, R=dR, alphas=d_as, betas=d_bs, c=d_c\n",
    "    )\n",
    "\n",
    "    return primal_output, tangent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Field: rs\n",
      "aprox: [-9.38230604e-07 -1.36983927e-01]\n",
      "exact: [ 0.         -0.13698954]\n",
      "- Field: alphas\n",
      "aprox: 0.35490620373113124\n",
      "exact: -0.009035158446323355\n",
      "- Field: ls\n",
      "aprox: [-0.11170777 -0.03778973 -0.26896889]\n",
      "exact: [-0.62078384  0.83186898 -1.349808  ]\n",
      "- Field: betas\n",
      "aprox: 0.4483334061422539\n",
      "exact: 0.30347325837350303\n",
      "field: c\n",
      "aprox: -0.40976143724003045\n",
      "exact: -0.40977729010234437\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(3, 2)\n",
    "da = np.random.randn(3, 2)\n",
    "start_vector = 1 * np.eye(2, 1).flatten()\n",
    "d_start_vector = np.random.randn(2)\n",
    "# d_start_vector = -2 * np.eye(2, 1, k=0).flatten()\n",
    "\n",
    "\n",
    "# numeric test\n",
    "h = 0.0001\n",
    "\n",
    "result, tangents = bidiagonalize_jvp(\n",
    "    primals=(A, start_vector), tangents=(da, d_start_vector)\n",
    ")\n",
    "result = bidiagonalize(A, start_vector)\n",
    "result_wiggled = bidiagonalize(A, start_vector + d_start_vector * h)\n",
    "\n",
    "\n",
    "fields = [\"rs\", \"alphas\", \"ls\", \"betas\"]\n",
    "\n",
    "for field in fields:\n",
    "    print(\"- Field:\", field)\n",
    "\n",
    "    # print(\"initial:\", result.__getattribute__(field)[1])\n",
    "    # print(\"wiggled:\", result_wiggled.__getattribute__(field)[1])\n",
    "\n",
    "    print(\n",
    "        \"aprox:\",\n",
    "        (result_wiggled.__getattribute__(field)[1] - result.__getattribute__(field)[1])\n",
    "        / h,\n",
    "    )\n",
    "\n",
    "    print(\"exact:\", tangents.__getattribute__(field)[1])\n",
    "\n",
    "print(\"field:\", \"c\")\n",
    "print(\n",
    "    \"aprox:\",\n",
    "    (result_wiggled.c - result.c) / h,\n",
    ")\n",
    "print(\"exact:\", tangents.c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Field: rs\n",
      "aprox: [-4.33431069e-07  9.31055351e-02]\n",
      "exact: [0.         0.09307973]\n",
      "-- Field: alphas\n",
      "aprox: 0.07314036367889187\n",
      "exact: 0.39033317241133014\n",
      "-- Field: ls\n",
      "aprox: [ 0.11427791  0.05928417 -0.15206785]\n",
      "exact: [ 0.86352674 -0.96384005  1.5244294 ]\n",
      "-- Field: betas\n",
      "aprox: 0.17390904949010633\n",
      "exact: -1.7229245117998953\n",
      "field: c\n",
      "aprox: 2.772419717826935\n",
      "exact: 2.77165173306653\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(3, 2)\n",
    "da = np.random.randn(3, 2)\n",
    "start_vector = 1 * np.eye(2, 1).flatten()\n",
    "d_start_vector = np.random.randn(2)\n",
    "# d_start_vector = -2 * np.eye(2, 1, k=0).flatten()\n",
    "\n",
    "result, tangents = bidiagonalize_jvp(\n",
    "    primals=(A, start_vector), tangents=(da, d_start_vector)\n",
    ")\n",
    "\n",
    "result_wiggled, _ = bidiagonalize_jvp(\n",
    "    primals=(A, start_vector + d_start_vector * h), tangents=(da, d_start_vector)\n",
    ")\n",
    "\n",
    "\n",
    "# numeric test\n",
    "\n",
    "fields = [\"rs\", \"alphas\", \"ls\", \"betas\"]\n",
    "\n",
    "for field in fields:\n",
    "    print(\"-- Field:\", field)\n",
    "\n",
    "    # print(\"initial:\", result.__getattribute__(field)[1])\n",
    "    # print(\"wiggled:\", result_wiggled.__getattribute__(field)[1])\n",
    "\n",
    "    print(\n",
    "        \"aprox:\",\n",
    "        (result_wiggled.__getattribute__(field)[1] - result.__getattribute__(field)[1])\n",
    "        / h,\n",
    "    )\n",
    "\n",
    "    print(\"exact:\", tangents.__getattribute__(field)[1])\n",
    "\n",
    "print(\"field:\", \"c\")\n",
    "print(\n",
    "    \"aprox:\",\n",
    "    (result_wiggled.c - result.c) / h,\n",
    ")\n",
    "print(\"exact:\", tangents.c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(3, 2)\n",
    "da = np.random.randn(3, 2)\n",
    "start_vector = 1 * np.eye(2, 1).flatten()\n",
    "d_start_vector = np.random.randn(2)\n",
    "\n",
    "result = bidiagonalize(A, start_vector)\n",
    "result__, _ = bidiagonalize_jvp((A, start_vector), (A, start_vector))\n",
    "\n",
    "print(np.array(result.alphas) - np.array(result__.alphas))\n",
    "print(np.array(result.betas) - np.array(result__.betas))\n",
    "print(np.array(result.rs) - np.array(result__.rs))\n",
    "print(np.array(result.ls) - np.array(result__.ls))\n",
    "print(np.array(result.c) - np.array(result__.c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
